# 阿里云通义千问模型参考

## 常用模型列表

### 推荐模型（按性价比排序）

#### 1. qwen-plus ⭐ 推荐
- **特点**：性价比最高，质量与速度平衡
- **适用场景**：日常翻译、一般文档
- **价格**：中等
- **推荐指数**：⭐⭐⭐⭐⭐

#### 2. qwen-max
- **特点**：最新版本，最高质量
- **适用场景**：专业文档、学术论文、重要翻译
- **价格**：较高
- **推荐指数**：⭐⭐⭐⭐

#### 3. qwen-turbo
- **特点**：快速响应，成本低
- **适用场景**：大批量翻译、简单文本
- **价格**：低
- **推荐指数**：⭐⭐⭐

### 指定版本模型

#### qwen2.5 系列

| 模型名称 | 参数量 | 特点 | 适用场景 |
|---------|--------|------|----------|
| qwen2.5-72b-instruct | 72B | 大参数，理解能力强 | 复杂翻译、专业领域 |
| qwen2.5-32b-instruct | 32B | 中等参数，平衡性能 | 一般专业翻译 |
| qwen2.5-14b-instruct | 14B | 小参数，快速响应 | 日常翻译 |
| qwen2.5-7b-instruct | 7B | 最小参数，成本最低 | 简单翻译 |

#### qwen2 系列（较旧版本）

| 模型名称 | 参数量 | 说明 |
|---------|--------|------|
| qwen2-72b-instruct | 72B | 上一代大参数模型 |
| qwen2-57b-a14b-instruct | 57B | 特殊版本 |
| qwen2-7b-instruct | 7B | 上一代小参数模型 |

### 长文本模型

| 模型名称 | 上下文长度 | 特点 |
|---------|-----------|------|
| qwen-long | 1M tokens | 超长上下文，适合长文档 |
| qwen2.5-72b-instruct | 128K tokens | 长上下文支持 |

---

## 如何选择模型？

### 按翻译质量需求

```
最高质量 → qwen-max
高质量   → qwen2.5-72b-instruct
平衡     → qwen-plus ⭐
快速     → qwen-turbo
```

### 按成本考虑

```
成本最低 → qwen-turbo
低成本   → qwen2.5-7b-instruct
中等     → qwen-plus ⭐
较高     → qwen-max
最高     → qwen2.5-72b-instruct
```

### 按文档类型

| 文档类型 | 推荐模型 |
|---------|---------|
| 学术论文 | qwen-max |
| 技术文档 | qwen-plus |
| 商务文档 | qwen-plus |
| 日常文档 | qwen-turbo |
| 长篇文档 | qwen-long |
| 专业领域 | qwen2.5-72b-instruct |

---

## 模型更新说明

阿里云会不断发布新模型，建议：

1. **查看最新模型列表**：
   - 访问：https://help.aliyun.com/zh/dashscope/developer-reference/model-square
   - 或在DashScope控制台查看

2. **测试新模型**：
   - 使用 `test_aliyun_api.py` 脚本测试
   - 对比翻译质量和速度

3. **灵活切换**：
   - 本应用支持手动输入任意模型名称
   - 可以随时尝试新发布的模型

---

## 使用示例

### 示例1：日常翻译
```
模型名称：qwen-plus
原因：性价比最高，质量足够好
```

### 示例2：专业论文
```
模型名称：qwen-max
原因：需要最高质量的翻译
```

### 示例3：大批量翻译
```
模型名称：qwen-turbo
原因：速度快，成本低
```

### 示例4：超长文档
```
模型名称：qwen-long
原因：支持超长上下文
```

### 示例5：技术文档
```
模型名称：qwen2.5-72b-instruct
原因：理解能力强，适合技术术语
```

---

## 价格参考

具体价格请访问阿里云官网：
https://dashscope.aliyun.com/pricing

一般规律：
- 参数量越大，价格越高
- 最新版本通常价格较高
- turbo系列价格最低
- max系列价格较高

---

## 常见问题

### Q: 如何知道模型是否可用？
A: 使用测试脚本：
```bash
python test_aliyun_api.py YOUR_KEY 模型名称
```

### Q: 模型名称输错了怎么办？
A: 会返回错误提示，重新配置正确的模型名称即可。

### Q: 可以使用未列出的模型吗？
A: 可以！只要是阿里云支持的模型，都可以手动输入使用。

### Q: 如何获取最新模型列表？
A: 
1. 访问阿里云DashScope文档
2. 查看模型广场
3. 或咨询阿里云技术支持

---

## 性能对比（参考）

基于一般使用经验：

| 指标 | qwen-turbo | qwen-plus | qwen-max | qwen2.5-72b |
|------|-----------|-----------|----------|-------------|
| 翻译质量 | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| 响应速度 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| 成本效益 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ | ⭐ |
| 综合推荐 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |

---

## 总结

**最佳实践**：
1. 日常使用：`qwen-plus`
2. 重要文档：`qwen-max`
3. 大批量：`qwen-turbo`
4. 专业领域：`qwen2.5-72b-instruct`

**灵活性**：
- 本应用支持手动输入任意模型名称
- 可以随时切换和测试不同模型
- 建议根据实际需求和预算选择

祝你翻译愉快！🎉

